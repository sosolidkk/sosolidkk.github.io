<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-11-24T20:36:27-03:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">João Pedro</title><subtitle>Hey there! Just created this place to share some thoughts and let my mind loose itself a little bit.  Don't take the things here too seriously. Enjoy your stay!</subtitle><entry><title type="html">Prime numbers</title><link href="http://localhost:4000/til/2020/06/22/primes.html" rel="alternate" type="text/html" title="Prime numbers" /><published>2020-06-22T18:32:03-03:00</published><updated>2020-06-22T18:32:03-03:00</updated><id>http://localhost:4000/til/2020/06/22/primes</id><content type="html" xml:base="http://localhost:4000/til/2020/06/22/primes.html">&lt;p&gt;Um número primo é um número natural maior que o 1 e que não é produto de dois números naturais menores que ele mesmo. Em outras palavras, é um número que é divisível somente por 1 e por ele mesmo. Como exemplo disso nós temos os números 2, 3, 5, 7, 11 e a lista segue. Quando um número não é primo, podemos dizer que ele é composto. Um número composto é um inteiro positivo que pode ser formado pela mutiplicações de dois números inteiros menores que ele mesmo. Em comparação com um número primo, é um número que é possível ser divisível por outro número além do 1 e dele mesmo. Todo número composto pode ser escrito pelo produto de dois ou mais (não necessariamente distintos) números primos. Por exemplo, 299 pode ser escrito como 13x23. Esse fato é chamado de &lt;a href=&quot;https://en.wikipedia.org/wiki/Fundamental_theorem_of_arithmetic&quot;&gt;teorema fundamental da aritmética&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Por um bom tempo não se era vistos casos de uso para os números primos fora do contexto da matemática (vale lembrar que a computação é bem recente quando colocado lado a lado no calendário das ciências) além do uso em engrenagens com números primos de dentes e outras possíveis situações. No entanto, por volta da década de 70 surgiram os primeiros estudos públicos informando que os números primos poderiam ser a base para algoritmos de criptografia de chave pública. Graças a isso, vários estudos foram surgindo principalmente no que diz respeito a testes de primalidade (nome dado a técnicas que buscam identificar um número primo) e na área da criptografia. Números primos também são utilizados em &lt;a href=&quot;https://en.wikipedia.org/wiki/Checksum&quot;&gt;checksums&lt;/a&gt;, &lt;a href=&quot;https://en.wikipedia.org/wiki/Hash_table&quot;&gt;hash tables&lt;/a&gt; e geração de números pseudo aleatórios.&lt;/p&gt;

&lt;p&gt;A técnica mais básica para verificar se um número é primo é o teste por divisão ou trial division. Esse método divide um inteiro n por cada inteiro existente entre o 2 até a raiz quadrada de n. Qualquer inteiro dentro desse intervalo que divida n de forma par, estabelece n como um número composto (não primo), caso contrário o mesmo é primo. Uma possível otimização para essa fórmula é realizar somente a divisão dos primos existentes no intervalo, por exemplo: para verificar se o número 37 é primo, vamos dividi-lo por todos os números primos entre 2 e √37, os quais são 2, 3 e 5. Se cada divisão produzir um resto, então o número é primo.&lt;/p&gt;

&lt;p&gt;Outro exemplo é o método chamado de Sieve of Eratosthenes. Dado um limite n, o algoritmo vai iterativamente marcando como composto os múltiplos de cada primo, iniciando pelo primeiro primo que é o 2. Os múltiplos de cada primo são gerados como uma sequência de números que partem do primeiro primo e vão se distanciando de forma constante de acordado com o valor do mesmo. Não entendeu? Segue uma ilustração.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/b/b9/Sieve_of_Eratosthenes_animation.gif&quot; alt=&quot;Sieve of Eratosthenes animation&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Crie uma lista de inteiros consecultivos que vai de 2 até n [2, 3, 4, … n];&lt;/li&gt;
  &lt;li&gt;p=2, o menor primo ou start point;&lt;/li&gt;
  &lt;li&gt;Encontre os multiplos de p contando de forma incremental indo de 2p até n, e marque eles [2p, 3p, 4p, …]. O próprio p não deve ser marcado;&lt;/li&gt;
  &lt;li&gt;Encontre o primeiro número maior que p na lista que não está marcado. Se esse número não existir, pare. Caso contrário, p vai ser igual a esse número e volte ao passo 3;&lt;/li&gt;
  &lt;li&gt;Ao fim do algoritmo, todos os números restantes não marcados na lista são primos abaixo do limite n.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Por fim, além da matemática e computação os números primos possuem conexões em potencial com mecânica quântica, e têm sido utilizados metaforicamente nas artes e literatura ao longo dos anos. Na biologia, existe um exemplo claro de estudo desses números que é o ciclo de vida das cigarras. Cigarras passam maior parte da sua vida enterradas no solo e emergem em ciclos de 7, 13 ou 17 anos para reproduzir, morrendo semanas após o ato. Biólogos afirmam que elas desenvolveram esse hábito para confundir predadores e evitar que eles tenham “consciência” ou sincronizem com o seu ciclo reprodutivo.&lt;/p&gt;</content><author><name></name></author><category term="TIL" /><summary type="html">Um número primo é um número natural maior que o 1 e que não é produto de dois números naturais menores que ele mesmo. Em outras palavras, é um número que é divisível somente por 1 e por ele mesmo. Como exemplo disso nós temos os números 2, 3, 5, 7, 11 e a lista segue. Quando um número não é primo, podemos dizer que ele é composto. Um número composto é um inteiro positivo que pode ser formado pela mutiplicações de dois números inteiros menores que ele mesmo. Em comparação com um número primo, é um número que é possível ser divisível por outro número além do 1 e dele mesmo. Todo número composto pode ser escrito pelo produto de dois ou mais (não necessariamente distintos) números primos. Por exemplo, 299 pode ser escrito como 13x23. Esse fato é chamado de teorema fundamental da aritmética.</summary></entry><entry><title type="html">Scraping vs Crawling</title><link href="http://localhost:4000/scraping/2020/05/18/scraping-vs-crawling.html" rel="alternate" type="text/html" title="Scraping vs Crawling" /><published>2020-05-18T22:02:37-03:00</published><updated>2020-05-18T22:02:37-03:00</updated><id>http://localhost:4000/scraping/2020/05/18/scraping-vs-crawling</id><content type="html" xml:base="http://localhost:4000/scraping/2020/05/18/scraping-vs-crawling.html">&lt;p&gt;Geralmente esses termos são difundidos de maneira equivocada. Para entender melhor, é necessário saber o que cada um deles significa. Scraping, ou aportuguesando um pouco podemos chegar em “garimpagem”, que é o ato de extrair informações e posteriormente salvá-las em algum local (geralmente uma base de dados) para depois serem analizadas. Basicamente, scraping não se limita somente a web já que é possível realizar scraping de um site, de um banco de dados, de arquivos, as opções são diversas. Já um crawler, popurlamente conhecido como bot ou spider (World wide web, spider, web, pegou o trocadilho?), vai buscar informações ou salvar páginas web completas para depois analizar as informações. Conseguiu perceber a diferença entre eles? Um crawler é exclusivamente para web e se difere tanto em escala quanto alcance de um simples script que realiza scraping.&lt;/p&gt;

&lt;p&gt;Para melhorar o entendimento, eu vou explicar o processo de funcionamento de um crawler.&lt;/p&gt;

&lt;p&gt;Um web crawler inicia com uma lista de URLs para visitar, conhecidas como seeds. A medida que o crawler visita essas URLs, ele primeiro vai buscar novos links para adicionar em uma outra lista chamada de crawl frontier ou fronteira de raspagem. Essa nova lista é uma estrutura de dados para salvar URLs que são elegíveis para raspagem. Caso não tenha ideia, compare a lista à uma fila de prioridade.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Essa fronteira é um dos componentes que torna possível a arquitetura de um crawler. Ela que contém a lógica e as políticas que as spiders seguem quando vão visitas os sites. Nas políticas é possível incluir coisas como qual página deve ser visitada, prioridades que devem ser buscadas em cada página e em qual frequência uma página deve ser visitada.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Após esse processo de salvamento das novas URLs, as spiders vão começar a arquivas as páginas (tipo o “Salvar como” de um navegador) em snapshots de modo que seja possível visualizar, ler e navegar como se fosse o próprio site.&lt;/p&gt;

&lt;p&gt;É necessário ter alguns cuidados quando se usa um web crawler:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;A internet é enorme. Todos os dias é criado conteúdo novo, muitas vezes sobre um mesmo assunto já existente que já foi postado e difundido em diversos blogs (como essa mesma explicação que eu estou fazendo). Com isso, é necessário se ter um cuidado extra na hora de programar um crawler para evitar um possível problema de duplicação de dados, seja no ato da captura ou no momento em que os dados serão salvos no banco de dados;&lt;/li&gt;
  &lt;li&gt;Aproveitando o gancho do ponto um, o número de sites que geram URLs pelo lado servidor (server-side) torna difícil o processo dos crawlers na tentativa de evitar conteúdo duplicado em suas buscas. Existem infintas combinações de parâmetros nas URLs, no qual apenas uma porção dessas vai de fato retornar um conteúdo único (que ainda não foi capturado ou que não se encontra no banco de daos). Por exemplo, uma galeria de fotos pode oferecer algumas opções para um usuário como:
    &lt;ul&gt;
      &lt;li&gt;Três modos de ordernas uma imagem;&lt;/li&gt;
      &lt;li&gt;Quatro escolhas de tamanho de thumbnail;&lt;/li&gt;
      &lt;li&gt;Cinco formatos de arquivos;&lt;/li&gt;
      &lt;li&gt;Com isso eu tenho um número enorme de URLs para acessar o mesmo conteúdo. Essa infinitude de combinações é um dos problemas que as spiders tem que enfrentar, visto que eles precisam ordernar entre várias URLs para trazer algo novo e único.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Outro problema é a coordenação das spiders para requisições sucessivas. Elas precisam ser “educadas” o suficiente para saber que existe um limite de requisição em todo servidor que eles permitem e eventualmente evitar um estresse desnecessário. Vale lembrar que todo site tem sua política e regras, no qual nem todos permitem fazer crawling de seu conteudo. Tenham isso em mente pois é muito importante;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Por fim, mas não menos importante, é necessário definir crawling agents, onde cada um irá gerenciar um nincho diferente de spiders e seus propósitos. Existem sites sobre os mais diversos assuntos e é indicado criar políticas de crawl para um desses sites.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Com isso, finalizo esse post e espero que tenha ficado um pouco mais clara a diferença entre esses dois termos.&lt;/p&gt;</content><author><name></name></author><category term="scraping" /><summary type="html">Geralmente esses termos são difundidos de maneira equivocada. Para entender melhor, é necessário saber o que cada um deles significa. Scraping, ou aportuguesando um pouco podemos chegar em “garimpagem”, que é o ato de extrair informações e posteriormente salvá-las em algum local (geralmente uma base de dados) para depois serem analizadas. Basicamente, scraping não se limita somente a web já que é possível realizar scraping de um site, de um banco de dados, de arquivos, as opções são diversas. Já um crawler, popurlamente conhecido como bot ou spider (World wide web, spider, web, pegou o trocadilho?), vai buscar informações ou salvar páginas web completas para depois analizar as informações. Conseguiu perceber a diferença entre eles? Um crawler é exclusivamente para web e se difere tanto em escala quanto alcance de um simples script que realiza scraping.</summary></entry></feed>